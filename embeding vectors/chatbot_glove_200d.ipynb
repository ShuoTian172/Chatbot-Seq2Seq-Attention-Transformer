{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "chatbot_glove_200d.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "kPPiCseB7eT_",
        "colab_type": "code",
        "outputId": "b5225935-dcc1-47c3-c7db-e4d8dd1ed088",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n",
        "from keras.models import Model, load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "d=200\n",
        "INPUT_LENGTH = d\n",
        "OUTPUT_LENGTH = d\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['glove-global-vectors-for-word-representation', 'cornell-moviedialog-corpus']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "9c5007896f6a9aaf3395fc82447ca2bb5cc57b65",
        "id": "0QfxeLEb7eUF",
        "colab_type": "text"
      },
      "source": [
        "### Resources:\n",
        "https://wanasit.github.io/attention-based-sequence-to-sequence-in-keras.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "nfYh7i877eUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data\n",
        "lines = open('../input/cornell-moviedialog-corpus/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "conv_lines = open('../input/cornell-moviedialog-corpus/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3983a4469fd5ed2f4b8db5a6cc41eda070c9142f",
        "id": "XRYQfcuE7eUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary to map each line's id with its text\n",
        "id2line = {}\n",
        "for line in lines:\n",
        "    _line = line.split(' +++$+++ ')\n",
        "    if len(_line) == 5:\n",
        "        id2line[_line[0]] = _line[4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "260fe85783607a5f8190796b4415dee00cdeabc5",
        "id": "-iJLxcSA7eUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a list of all of the conversations' lines' ids.\n",
        "convs = []\n",
        "for line in conv_lines[:-1]:\n",
        "    _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
        "    convs.append(_line.split(','))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "c7ac8d38b75b1101165c37cdab3fca42597eb4d7",
        "id": "GIeQ0h2X7eUN",
        "colab_type": "code",
        "outputId": "4d3b9a2b-039f-4e4d-c9a8-afcada0b6b65",
        "colab": {}
      },
      "source": [
        "#id and conversation sample\n",
        "for k in convs[300]:\n",
        "    print (k, id2line[k])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L3490 That's what he did to me.  He put cigarettes out on me.\n",
            "L3491 Your father put cigarettes out on you?\n",
            "L3492 Out on my back when I was a small boy.\n",
            "L3493 Can I see your back?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a3142e705c67fd80837a998a7884dd584c30f57c",
        "id": "t36vPyQJ7eUR",
        "colab_type": "code",
        "outputId": "ee7e3413-86bd-4654-bb3c-bffc42495b59",
        "colab": {}
      },
      "source": [
        "# Sort the sentences into questions (inputs) and answers (targets)\n",
        "questions = []\n",
        "answers = []\n",
        "for conv in convs:\n",
        "    for i in range(len(conv)-1):\n",
        "        questions.append(id2line[conv[i]])\n",
        "        answers.append(id2line[conv[i+1]])\n",
        "        \n",
        "# Compare lengths of questions and answers\n",
        "\n",
        "print(len(questions))\n",
        "print(len(answers))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "221616\n",
            "221616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "85f3e1713f0620f066f5a5ee34b31c9a73d768fa",
        "id": "2U0SZ-OJ7eUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|]\", \"\", text)\n",
        "#     text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "162b9f09f2e3e50ed92f157a5ce0faf3bb0d0019",
        "id": "_1TF_y0f7eUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean the data\n",
        "clean_questions = []\n",
        "for question in questions:\n",
        "    clean_questions.append(clean_text(question))\n",
        "clean_answers = []    \n",
        "for answer in answers:\n",
        "    clean_answers.append(clean_text(answer))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "0035c49ba3da36e903a600b22c737e6a5c34de6e",
        "id": "UhgrUF0p7eUa",
        "colab_type": "code",
        "outputId": "63a6d37c-4c07-4873-af96-d1bbaa267cdf",
        "colab": {}
      },
      "source": [
        "# Remove questions and answers that are shorter than 1 word and longer than 20 words.\n",
        "min_line_length = 2\n",
        "max_line_length = 20\n",
        "\n",
        "# Filter out the questions that are too short/long\n",
        "short_questions_temp = []\n",
        "short_answers_temp = []\n",
        "\n",
        "for i, question in enumerate(clean_questions):\n",
        "    if len(question.split()) >= min_line_length and len(question.split()) <= max_line_length:\n",
        "        short_questions_temp.append(question)\n",
        "        short_answers_temp.append(clean_answers[i])\n",
        "\n",
        "# Filter out the answers that are too short/long\n",
        "short_questions = []\n",
        "short_answers = []\n",
        "\n",
        "for i, answer in enumerate(short_answers_temp):\n",
        "    if len(answer.split()) >= min_line_length and len(answer.split()) <= max_line_length:\n",
        "        short_answers.append(answer)\n",
        "        short_questions.append(short_questions_temp[i])\n",
        "        \n",
        "print(len(short_questions))\n",
        "print(len(short_answers))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "138528\n",
            "138528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "85389732fd564d7b160339bb26d0d1b5dea41fe7",
        "id": "8EO_82hr7eUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del convs\n",
        "del id2line \n",
        "del clean_questions\n",
        "del clean_answers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5825a5967e5a04f13b0a755e8ba304c419af4b33",
        "id": "qz2gpwkA7eUh",
        "colab_type": "text"
      },
      "source": [
        "### 1.1  Preprocessing for word based model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "106248b9b0ac7499c2b34cc3ae1c20a2e0ea41c4",
        "id": "I0AA84Zy7eUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "#choosing number of samples\n",
        "num_samples = 20000  # Number of samples to train on.\n",
        "short_questions = short_questions[:num_samples]\n",
        "short_answers = short_answers[:num_samples]\n",
        "\n",
        "#tokenizing the qns and answers\n",
        "short_questions_tok = [nltk.word_tokenize(sent) for sent in short_questions]\n",
        "short_answers_tok = [nltk.word_tokenize(sent) for sent in short_answers]\n",
        "#分词\n",
        "data_size = len(short_questions_tok)\n",
        "training_input  = short_questions_tok[:round(data_size*(80/100))]\n",
        "training_input  = [tr_input[::-1] for tr_input in training_input] #reverseing input seq for better performance\n",
        "training_output = short_answers_tok[:round(data_size*(80/100))]\n",
        "\n",
        "# We will use the remaining for validation\n",
        "validation_input = short_questions_tok[round(data_size*(80/100)):]\n",
        "validation_input  = [val_input[::-1] for val_input in validation_input] #reverseing input seq for better performance\n",
        "validation_output = short_answers_tok[round(data_size*(80/100)):]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a3aacc0315837faf77599da087f8b3a52d217859",
        "id": "sS3w2W6c7eUm",
        "colab_type": "text"
      },
      "source": [
        "### 1.2  Word en/decoding dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "51918567f4f43ae13a8d58a00bda15b1d508b191",
        "id": "2YinWobM7eUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary for the frequency of the vocabulary\n",
        "# Create \n",
        "vocab = {}\n",
        "for question in short_questions_tok:\n",
        "    for word in question:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1\n",
        "\n",
        "for answer in short_answers_tok:\n",
        "    for word in answer:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "30d25056e8f62453bcde0a16c8a7933275f431c9",
        "id": "TlZO4ESU7eUp",
        "colab_type": "code",
        "outputId": "26f70ed1-3404-4101-bab6-af25b6caaf74",
        "colab": {}
      },
      "source": [
        "# Remove rare words from the vocabulary.\n",
        "# We will aim to replace fewer than 5% of words with <UNK>\n",
        "# You will see this ratio soon.\n",
        "WORD_CODE_START = 1\n",
        "WORD_CODE_PADDING = 0\n",
        "\n",
        "threshold = 5\n",
        "count = 0\n",
        "for k,v in vocab.items():\n",
        "    if v >= threshold:\n",
        "        count += 1\n",
        "        word_num  = 2 #number 1 is left for WORD_CODE_START for model decoder later\n",
        "encoding = {}\n",
        "decoding = {1: 'START'}\n",
        "for word, count in vocab.items():\n",
        "    if count >= threshold: #get vocabularies that appear above threshold count\n",
        "        encoding[word] = word_num \n",
        "        decoding[word_num ] = word\n",
        "        word_num += 1\n",
        "decoding[len(encoding)+2] = '<UNK>'\n",
        "encoding['<UNK>'] = len(encoding)+2\n",
        "dict_size = word_num+1\n",
        "dict_size\n",
        "print(len(vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdlBAOvv7eUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(encoding, data, vector_size):\n",
        "   \n",
        "    transformed_data = np.zeros(shape=(len(data), vector_size))\n",
        "    for i in range(len(data)):\n",
        "        for j in range(min(len(data[i]), vector_size)):\n",
        "            try:\n",
        "                transformed_data[i][j] = encoding[data[i][j]]\n",
        "            except:\n",
        "                transformed_data[i][j] = encoding['<UNK>']\n",
        "    return transformed_data\n",
        "encoded_training_input = transform(\n",
        "    encoding, training_input, vector_size=INPUT_LENGTH)\n",
        "encoded_training_output = transform(\n",
        "    encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
        "encoded_validation_input = transform(\n",
        "    encoding, validation_input, vector_size=INPUT_LENGTH)\n",
        "encoded_validation_output = transform(\n",
        "    encoding, validation_output, vector_size=OUTPUT_LENGTH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydQEUP987eUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7ea3c32a6180ee8fea8b1490b40351897cc426e6",
        "id": "a4UpqK_i7eUw",
        "colab_type": "text"
      },
      "source": [
        "### 1.3  Vectorizing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQiztHtu7eUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = {}\n",
        "f = open('../input/glove-global-vectors-for-word-representation/glove.6B.200d.txt')\n",
        "#chang the path to different dimension glove pre-trained model\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:], dtype='float32')\n",
        "    #print(vector)\n",
        "    embeddings[word] = vector\n",
        "f.close()\n",
        "#print(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4de33f91476bd6c50cf7c9322f273079783ceec2",
        "id": "c9pAbOYD7eUz",
        "colab_type": "code",
        "outputId": "bd662b17-f08e-45c1-c6c7-6499ce048ae0",
        "colab": {}
      },
      "source": [
        "\n",
        "#encoded_training_input = np.random.uniform(-0.05, 0.05, size=(len(training_input), d)) \n",
        "#encoded_training_output= np.random.uniform(-0.05, 0.05, size=(len(training_output), d)) \n",
        "encoder_embeddings_matrix = np.random.uniform(-0.05, 0.05, size=(len(encoding)+1, d)) \n",
        "\n",
        "for word, i in encoding.items(): # i=0 is the embedding for the zero padding\n",
        "    try:\n",
        "        embeddings_vector = embeddings[word]\n",
        "    except KeyError:\n",
        "        embeddings_vector = None\n",
        "    if embeddings_vector is not None:\n",
        "        encoder_embeddings_matrix[i] = embeddings_vector\n",
        "print(encoder_embeddings_matrix)\n",
        "\n",
        "decoder_embeddings_matrix = np.random.uniform(-0.05, 0.05, size=(len(decoding)+1, d)) \n",
        "\n",
        "for word, i in decoding.items(): # i=0 is the embedding for the zero padding\n",
        "    try:\n",
        "        embeddings_vector = embeddings[word]\n",
        "    except KeyError:\n",
        "        embeddings_vector = None\n",
        "    if embeddings_vector is not None:\n",
        "        decoder_embeddings_matrix[i] = embeddings_vector\n",
        "print(decoder_embeddings_matrix)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.02091818  0.04886338  0.01128049 ... -0.00426531 -0.04118453\n",
            "   0.00296796]\n",
            " [ 0.02266394  0.03649937 -0.04902619 ...  0.03902137  0.03908685\n",
            "  -0.04419164]\n",
            " [ 0.14145     0.17779     0.015949   ...  0.033666    0.077406\n",
            "   0.41016999]\n",
            " ...\n",
            " [-0.2445     -1.05429995 -0.63563001 ... -0.18542001 -0.31465\n",
            "  -0.0040284 ]\n",
            " [-0.19162001  0.43301001 -0.43311    ...  0.070339   -0.024414\n",
            "  -0.22346   ]\n",
            " [ 0.2802      0.32108     0.59482002 ... -0.072394    0.29179001\n",
            "  -0.13476001]]\n",
            "[[-0.00945781 -0.01042366  0.03057535 ... -0.0380896  -0.04692658\n",
            "  -0.02120648]\n",
            " [-0.04627849  0.02341359  0.01290885 ... -0.04292509  0.02232446\n",
            "   0.00226963]\n",
            " [-0.00659843  0.04586526  0.01445167 ... -0.00067948  0.00376555\n",
            "   0.04203488]\n",
            " ...\n",
            " [-0.00549319 -0.04102784  0.00134535 ... -0.04641223  0.01261138\n",
            "  -0.01191673]\n",
            " [ 0.03796911  0.01956759  0.02559582 ...  0.01762391 -0.00566132\n",
            "  -0.01850831]\n",
            " [-0.04200012 -0.03955213 -0.02418059 ...  0.03714501 -0.03318958\n",
            "   0.00449422]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b52f0368fecf8ac79903927799fe67c104d8e518",
        "id": "f1ykA__s7eU4",
        "colab_type": "text"
      },
      "source": [
        "## 2  Model Building\n",
        "### 2.1  Sequence-to-Sequence in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "306b1fb012febd74dd40840c0588bdd8503ba65b",
        "id": "Q2IyUGA27eU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.backend import clear_session\n",
        "clear_session()\n",
        "\n",
        "\n",
        "\n",
        "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
        "decoder_input = Input(shape=(OUTPUT_LENGTH,))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d91367ec6c706059c4b520011fdec6e1051db38d",
        "id": "blMygQUK7eU8",
        "colab_type": "code",
        "outputId": "ac6a5b12-a5f1-4f44-9d6c-c588fedeeb84",
        "colab": {}
      },
      "source": [
        "from keras.layers import SimpleRNN\n",
        "\n",
        "encoder = Embedding(dict_size-1, d, input_length=INPUT_LENGTH, weights = [encoder_embeddings_matrix], mask_zero=True)(encoder_input)\n",
        "encoder = LSTM(512, return_sequences=True, unroll=True)(encoder)\n",
        "encoder_last = encoder[:,-1,:]\n",
        "\n",
        "print('encoder', encoder)\n",
        "print('encoder_last', encoder_last)\n",
        "\n",
        "decoder = Embedding(dict_size, d, input_length=OUTPUT_LENGTH,weights = [decoder_embeddings_matrix], mask_zero=True)(decoder_input)\n",
        "decoder = LSTM(512, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
        "\n",
        "print('decoder', decoder)\n",
        "\n",
        "# For the plain Sequence-to-Sequence, we produced the output from directly from decoder\n",
        "# output = TimeDistributed(Dense(output_dict_size, activation=\"softmax\"))(decoder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder Tensor(\"lstm_1/transpose_2:0\", shape=(?, 200, 512), dtype=float32)\n",
            "encoder_last Tensor(\"strided_slice:0\", shape=(?, 512), dtype=float32)\n",
            "decoder Tensor(\"lstm_2/transpose_2:0\", shape=(?, 200, 512), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2feb58fa60a8ff335b218114808aa2d3e4d37461",
        "id": "NAOn5cWk7eVB",
        "colab_type": "text"
      },
      "source": [
        "### 2.2  Attention Mechanism\n",
        "Reference: Effective Approaches to Attention-based Neural Machine Translation's Global Attention with Dot-based scoring function (Section 3, 3.1) https://arxiv.org/pdf/1508.04025.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVRzbctl7eVB",
        "colab_type": "code",
        "outputId": "da00b8b3-818d-4490-c601-989a8d701b56",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation, dot, concatenate\n",
        "\n",
        "# Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
        "# Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
        "attention = dot([decoder, encoder], axes=[2, 2])\n",
        "attention = Activation('softmax', name='attention')(attention)\n",
        "print('attention', attention)\n",
        "\n",
        "context = dot([attention, encoder], axes=[2,1])\n",
        "print('context', context)\n",
        "\n",
        "decoder_combined_context = concatenate([context, decoder])\n",
        "print('decoder_combined_context', decoder_combined_context)\n",
        "\n",
        "# Has another weight + tanh layer as described in equation (5) of the paper\n",
        "output = TimeDistributed(Dense(512, activation=\"tanh\"))(decoder_combined_context)\n",
        "output = TimeDistributed(Dense(dict_size, activation=\"softmax\"))(output)\n",
        "print('output', output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention Tensor(\"attention/truediv:0\", shape=(?, 200, 200), dtype=float32)\n",
            "context Tensor(\"dot_2/MatMul:0\", shape=(?, 200, 512), dtype=float32)\n",
            "decoder_combined_context Tensor(\"concatenate_1/concat:0\", shape=(?, 200, 1024), dtype=float32)\n",
            "output Tensor(\"time_distributed_2/Reshape_1:0\", shape=(?, 200, 3635), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "257dcf12770f8928f91754044d3efc5aff1ec296",
        "id": "6AXifcUx7eVE",
        "colab_type": "code",
        "outputId": "c091c657-f64e-441e-fafe-861419f23194",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 200)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            (None, 200)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 200, 200)     727000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 200, 200)     726800      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 200, 512)     1460224     embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 200, 512)     1460224     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 200, 200)     0           lstm_2[0][0]                     \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention (Activation)          (None, 200, 200)     0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dot_2 (Dot)                     (None, 200, 512)     0           attention[0][0]                  \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 200, 1024)    0           dot_2[0][0]                      \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 200, 512)     524800      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 200, 3635)    1864755     time_distributed_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 6,763,803\n",
            "Trainable params: 6,763,803\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFB_jqOE7eVI",
        "colab_type": "code",
        "outputId": "e3aa5e17-4dc3-4944-fa02-14fae577b022",
        "colab": {}
      },
      "source": [
        "training_encoder_input = encoded_training_input\n",
        "training_decoder_input = np.zeros_like(encoded_training_output)\n",
        "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
        "training_decoder_input[:, 0] = WORD_CODE_START\n",
        "training_decoder_output =np.eye(dict_size)[encoded_training_output.astype('int')]\n",
        "\n",
        "validation_encoder_input = encoded_validation_input\n",
        "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
        "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
        "validation_decoder_input[:, 0] = WORD_CODE_START \n",
        "validation_decoder_output = np.eye(dict_size)[encoded_validation_output.astype('int')]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MemoryError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-912eb00e78f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtraining_decoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_training_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraining_decoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWORD_CODE_START\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtraining_decoder_output\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoded_training_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalidation_encoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_validation_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMemoryError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAyg2K7Q7eVK",
        "colab_type": "code",
        "outputId": "fd5214ca-c8ec-4122-a01f-07cb607e6854",
        "colab": {}
      },
      "source": [
        "model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
        "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
        "          #validation_split=0.05,\n",
        "          batch_size=64, epochs=50)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'training_decoder_output' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6cc81b6b208e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_encoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_decoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalidation_decoder_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0;31m#validation_split=0.05,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           batch_size=64, epochs=50)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_decoder_output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWCbjK467eVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "874f0398f10f48cce993bcd9aa7b5e0644b6f292",
        "collapsed": true,
        "id": "7EzY1gg17eVP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d0e3217f3d250c253dd457f192f54f8cd67c630f",
        "id": "xafY98TN7eVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "\n",
        "def prediction(raw_input):\n",
        "    clean_input = clean_text(raw_input)\n",
        "    #print(clean_input)\n",
        "    input_tok = [nltk.word_tokenize(clean_input)]\n",
        "    input_tok = [input_tok[0][::-1]]  #reverseing input seq\n",
        "    encoder_input = transform(encoding, input_tok, d)\n",
        "    #print(encoder_input)\n",
        "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
        "    decoder_input[:,0] = WORD_CODE_START\n",
        "    for i in range(1, OUTPUT_LENGTH):\n",
        "        #print(encoder_input)\n",
        "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
        "        decoder_input[:,i] = output[:,i]\n",
        "    return output\n",
        "\n",
        "def decode(decoding, vector):\n",
        "    \n",
        "    text = ''\n",
        "    for i in vector:\n",
        "        if i == 0:\n",
        "            break\n",
        "        text += ' '\n",
        "        text += decoding[i]\n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM-3kXF-7eVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "16e6ece57e4c02321c58176e5471f37ad1170837",
        "id": "tXpZwPUd7eVV",
        "colab_type": "code",
        "outputId": "19489fa9-e968-4a54-8a01-305c95a5a820",
        "colab": {}
      },
      "source": [
        "test_que=[]\n",
        "test_ans=[]\n",
        "test_r=[]\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "for i in range(200):\n",
        "    output = prediction(TreebankWordDetokenizer().detokenize(validation_input[i]))\n",
        "    q=validation_input[i]\n",
        "    a=decode(decoding, output[0])\n",
        "    r=validation_output[i]\n",
        "    test_que.append(q)\n",
        "    test_ans.append(a)\n",
        "    test_r.append(r)\n",
        "tok_r=[]\n",
        "tok_ans = [nltk.word_tokenize(sent) for sent in test_ans]\n",
        "for i in range (0,len(test_r)):\n",
        "    p=test_r[i]\n",
        "    tok_r.append([p])\n",
        "print(tok_ans[:9])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils'], ['bright', 'department', 'admire', 'department', 'department', 'admire', 'department', 'admire', 'department', 'department', 'admire', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'department', 'department', 'admire', 'admire'], ['bright', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows'], ['windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows', 'windows'], ['outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta'], ['bright', 'bright', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta', 'outta'], ['bright', 'bright', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov', 'pimenov'], ['department', 'department', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils', 'pupils'], ['bright', 'fbi', 'fbi', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'fbi', 'admire', 'admire', 'fbi', 'admire', 'admire']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMx7PTN27eVZ",
        "colab_type": "code",
        "outputId": "c1c2314d-a31d-44e2-efb8-b2838dfac53e",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "reference = tok_r\n",
        "candidate = tok_ans\n",
        "print('Cumulative 1-gram: %f' % corpus_bleu(reference, candidate))\n",
        "print('Cumulative 2-gram: %f' % corpus_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0)))\n",
        "print('Cumulative 3-gram: %f' % corpus_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0)))\n",
        "print('Cumulative 4-gram: %f' % corpus_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cumulative 1-gram: 0.000000\n",
            "Cumulative 2-gram: 0.000000\n",
            "Cumulative 3-gram: 0.000000\n",
            "Cumulative 4-gram: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}